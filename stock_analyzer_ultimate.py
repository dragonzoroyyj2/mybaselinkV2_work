import os
import sys
import json
import time
import logging
import argparse
import traceback
from pathlib import Path 
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed
import io
import base64

# ==============================
# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸ ë° ì„í¬íŠ¸
# ==============================
try:
    import FinanceDataReader as fdr
    import pandas as pd
    import mplfinance as mpf
    import matplotlib.pyplot as plt
    import numpy as np
    from scipy.signal import find_peaks
    import yfinance as yf
    
    # DART ê³µì‹œ í•„í„°ë§ (í™˜ê²½ ë³€ìˆ˜ í™•ì¸)
    DART_API_KEY = os.getenv("DART_API_KEY") 
    DART_AVAILABLE = bool(DART_API_KEY)
    if DART_AVAILABLE:
        try:
            from dart_fss import Dart
        except ImportError:
            DART_AVAILABLE = False
            logging.warning("DART_API_KEYê°€ ì„¤ì •ë˜ì—ˆìœ¼ë‚˜ dart-fss ëª¨ë“ˆì´ ì—†ì–´ DART ê¸°ëŠ¥ ë¹„í™œì„±í™”.")

except ModuleNotFoundError as e:
    sys.stdout.write(json.dumps({"error": f"í•„ìˆ˜ ëª¨ë“ˆ ëˆ„ë½: {e.name} ì„¤ì¹˜ í•„ìš” (pip install {e.name})"}, ensure_ascii=False) + "\n")
    sys.exit(1)

# ==============================
# 2. ê²½ë¡œ ë° ìƒìˆ˜ ì„¤ì •
# ==============================
BASE_DIR = Path(__file__).resolve().parent if Path(__file__).name != '<stdin>' else Path.cwd()
LOG_DIR = BASE_DIR / "log"
DATA_DIR = BASE_DIR / "data" / "stock_data"
LISTING_FILE = BASE_DIR / "data" / "stock_list" / "stock_listing.json"
LOG_FILE = LOG_DIR / "stock_analyzer_ultimate.log"

# ==============================
# 3. í™˜ê²½ ì´ˆê¸°í™” ë° ìœ í‹¸ë¦¬í‹°
# ==============================
def setup_env():
    LOG_DIR.mkdir(parents=True, exist_ok=True)
    DATA_DIR.mkdir(parents=True, exist_ok=True)
    LISTING_FILE.parent.mkdir(parents=True, exist_ok=True)
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(levelname)s - %(message)s",
        handlers=[
            logging.FileHandler(LOG_FILE, encoding="utf-8"),
            logging.StreamHandler(sys.stdout)
        ]
    )
def safe_print_json(data):
    """í‘œì¤€ ì¶œë ¥(stdout)ìœ¼ë¡œ JSONì„ ì•ˆì „í•˜ê²Œ ì¶œë ¥"""
    sys.stdout.write(json.dumps(data, ensure_ascii=False, indent=2) + "\n")
    sys.stdout.flush()

def set_korean_font():
    if sys.platform.startswith('win'): font_family = 'Malgun Gothic'
    elif sys.platform.startswith('darwin'): font_family = 'AppleGothic'
    else: font_family = 'NanumGothic'
    try:
        plt.rc('font', family=font_family)
        plt.rcParams['axes.unicode_minus'] = False
        global MPLFINANCE_FONT
        MPLFINANCE_FONT = font_family
    except Exception: pass
MPLFINANCE_FONT = 'sans-serif' 
set_korean_font()
setup_env() 

def load_listing():
    if not LISTING_FILE.exists(): 
        logging.error(f"ì¢…ëª© ë¦¬ìŠ¤íŠ¸ íŒŒì¼ ì—†ìŒ: {LISTING_FILE}")
        return [{"Code": "005930", "Name": "ì‚¼ì„±ì „ì", "DartCorpCode": "00126380"}] 
    with open(LISTING_FILE, "r", encoding="utf-8") as f: return json.load(f)

def get_stock_name(symbol):
    try:
        items = load_listing()
        for item in items:
            code = item.get("Code") or item.get("code")
            if code == symbol: return item.get("Name") or item.get("name")
        return symbol
    except Exception: return symbol

def get_dart_corp_code(symbol):
    try:
        items = load_listing()
        for item in items:
            code = item.get("Code") or item.get("code")
            if code == symbol: return item.get("DartCorpCode")
        return None
    except Exception: return None


# ==============================
# 4. ê¸°ìˆ ì  ë¶„ì„ íŒ¨í„´ ë¡œì§ (ìƒëµ ì—†ì´ ëª¨ë‘ í¬í•¨)
# ==============================
def find_peaks_and_troughs(df, prominence=0.01, width=3):
    """ì£¼ìš” ë´‰ìš°ë¦¬ì™€ ê³¨ì§œê¸° ì¸ë±ìŠ¤ ì°¾ê¸°"""
    recent_df = df.iloc[-250:].copy()
    if recent_df.empty: return np.array([]), np.array([])
    
    std_dev = recent_df['Close'].std()
    # prominence ê¸°ì¤€ì„ ì¢…ëª©ë³„ ë³€ë™ì„±ì— ë§ì¶° ìë™ ì¡°ì •
    peaks, _ = find_peaks(recent_df['Close'], prominence=std_dev * prominence, width=width)
    troughs, _ = find_peaks(-recent_df['Close'], prominence=std_dev * prominence, width=width)
    
    start_idx = len(df) - len(recent_df)
    return peaks + start_idx, troughs + start_idx

def find_double_bottom(df, troughs, tolerance=0.05, min_duration=30):
    """
    ğŸ“ˆ ì´ì¤‘ ë°”ë‹¥ íŒ¨í„´ ê°ì§€ (íŠœë‹: tolerance 5%, ìµœì†Œ ê¸°ê°„ 30ì¼)
    """
    recent_troughs = [t for t in troughs if t >= len(df) - 250]
    if len(recent_troughs) < 2: return False, None, None, None
    
    idx2, idx1 = recent_troughs[-1], recent_troughs[-2] 
    price1, price2 = df['Close'].iloc[idx1], df['Close'].iloc[idx2]
    
    if idx2 - idx1 < min_duration: return False, None, None, None
    
    is_price_matching = abs(price1 - price2) / min(price1, price2) < tolerance
    if not is_price_matching: return False, None, None, None
    
    interim_high = df['Close'].iloc[idx1:idx2].max()
    current_price = df['Close'].iloc[-1]

    is_breakout = current_price > interim_high
    
    if is_breakout: return True, interim_high, 'Breakout', interim_high
    
    retrace_ratio = (current_price - min(price1, price2)) / (interim_high - min(price1, price2))
    is_potential = retrace_ratio > 0.5 and current_price < interim_high 
    
    if is_potential: return False, interim_high, 'Potential', interim_high
        
    return False, None, None, None

def find_triple_bottom(df, troughs, tolerance=0.05, min_duration_total=75):
    """
    ğŸ§± ì‚¼ì¤‘ ë°”ë‹¥ íŒ¨í„´ ê°ì§€ (íŠœë‹: tolerance 5%, ìµœì†Œ ê¸°ê°„ 75ì¼)
    """
    recent_troughs = [t for t in troughs if t >= len(df) - 250]
    if len(recent_troughs) < 3: return False, None, None, None
    
    idx3, idx2, idx1 = recent_troughs[-1], recent_troughs[-2], recent_troughs[-3]
    price1, price2, price3 = df['Close'].iloc[idx1], df['Close'].iloc[idx2], df['Close'].iloc[idx3]
    
    if idx3 - idx1 < min_duration_total: return False, None, None, None
    
    min_price = min(price1, price2, price3)
    max_price = max(price1, price2, price3)
    is_price_matching = (max_price - min_price) / min_price < tolerance
    if not is_price_matching: return False, None, None, None
    
    high1 = df['Close'].iloc[idx1:idx2].max()
    high2 = df['Close'].iloc[idx2:idx3].max()
    neckline = max(high1, high2)
    current_price = df['Close'].iloc[-1]

    is_breakout = current_price > neckline
    
    if is_breakout: return True, neckline, 'Breakout', neckline
    
    retrace_ratio = (current_price - min_price) / (neckline - min_price)
    is_potential = retrace_ratio > 0.5 and current_price < neckline
    
    if is_potential: return False, neckline, 'Potential', neckline
        
    return False, None, None, None


def find_cup_and_handle(df, peaks, troughs, min_cup_depth=0.15, handle_drop_ratio=0.3):
    """
    â˜• ì»µ ì•¤ í•¸ë“¤ íŒ¨í„´ ê°ì§€ (íŠœë‹: ì»µ ê¹Šì´ ìµœì†Œ 15%, í•¸ë“¤ ì¡°ì • í­ ìµœëŒ€ 30%)
    """
    recent_peaks = [p for p in peaks if p >= len(df) - 250]
    if len(recent_peaks) < 2: return False, None, None, None
    
    peak_right_idx = recent_peaks[-1]
    peak_right_price = df['Close'].iloc[peak_right_idx]
    
    cup_troughs = [t for t in troughs if t < peak_right_idx]
    if not cup_troughs: return False, None, None, None
    
    cup_bottom_idx = cup_troughs[np.argmin(df['Close'].iloc[cup_troughs])]
    cup_bottom_price = df['Close'].iloc[cup_bottom_idx]
    
    cup_depth = (peak_right_price - cup_bottom_price) / peak_right_price
    if cup_depth < min_cup_depth: return False, None, None, None
    
    handle_start_idx = peak_right_idx 
    handle_max_drop = peak_right_price * (1 - handle_drop_ratio) 

    current_price = df['Close'].iloc[-1]
    
    is_handle_forming = (df['Close'].iloc[handle_start_idx:].max() <= peak_right_price) 
    is_handle_forming &= (current_price > handle_max_drop)

    if is_handle_forming and current_price > peak_right_price:
        return True, peak_right_price, 'Breakout', peak_right_price
    
    if is_handle_forming and current_price <= peak_right_price:
        return False, peak_right_price, 'Potential', peak_right_price
        
    return False, None, None, None

# ==============================
# 5. ê¸°ë³¸ì  ë¶„ì„ ë° ì•…ì¬ í•„í„°ë§ ë¡œì§ (ìƒëµ ì—†ì´ ëª¨ë‘ í¬í•¨)
# ==============================

def get_financial_statements_fdr(code):
    """FinanceDataReaderë¥¼ ì´ìš©í•´ ì¬ë¬´ ë¹„ìœ¨ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    fundamentals = {}
    try:
        df_fin = fdr.financials.get_financial_statements(code, 'Annual', 'KOR')
        if df_fin is None or df_fin.empty: return fundamentals
        latest_col = df_fin.columns[-1]

        total_debt = df_fin.loc['ë¶€ì±„ì´ê³„', latest_col] if 'ë¶€ì±„ì´ê³„' in df_fin.index else np.nan
        total_equity = df_fin.loc['ìë³¸ì´ê³„', latest_col] if 'ìë³¸ì´ê³„' in df_fin.index else np.nan
        if not pd.isna(total_debt) and not pd.isna(total_equity) and total_equity != 0:
            fundamentals['DebtToEquity'] = (total_debt / total_equity) * 100
        
        net_income = df_fin.loc['ë‹¹ê¸°ìˆœì´ìµ', latest_col] if 'ë‹¹ê¸°ìˆœì´ìµ' in df_fin.index else np.nan
        if not pd.isna(net_income) and not pd.isna(total_equity) and total_equity != 0:
            fundamentals['ROE'] = (net_income / total_equity) * 100
        
    except Exception as e:
        logging.warning(f"FDR ì¬ë¬´ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ ({code}): {e}")
        
    return fundamentals

def get_yfinance_news(code):
    """yfinanceë¥¼ ì´ìš©í•´ ìµœê·¼ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    headlines = []
    try:
        yf_ticker = f"{code}.KS" if not code.endswith('.KS') else code
        ticker = yf.Ticker(yf_ticker)
        news_list = ticker.news
        filtered_headlines = []
        two_months_ago = datetime.now() - timedelta(days=60)
        for news in news_list:
            publish_date = datetime.fromtimestamp(news.get('providerPublishTime')) 
            if publish_date >= two_months_ago:
                filtered_headlines.append({"title": news.get('title'), "link": news.get('link')})
            if len(filtered_headlines) >= 3: break
        return filtered_headlines
    except Exception as e:
        logging.warning(f"yfinance ë‰´ìŠ¤ ë¡œë“œ ì‹¤íŒ¨ ({code}): {e}")
        return []

def get_fundamental_data(code):
    fundamentals = get_financial_statements_fdr(code)
    headlines = get_yfinance_news(code)
    return fundamentals, headlines

def check_for_negative_dart_disclosures(corp_code):
    """DART ê³µì‹œì—ì„œ ì•…ì¬ì„± í‚¤ì›Œë“œ ê²€ì‚¬ (í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©)"""
    if not DART_AVAILABLE or not corp_code or not DART_API_KEY: return False, None
    try:
        dart = Dart(DART_API_KEY)
        end_date = datetime.now()
        start_date = end_date - timedelta(days=60)
        reports = dart.search(corp_code=corp_code, start_dt=start_date.strftime('%Y%m%d'))
        negative_keywords = ["íš¡ë ¹", "ë°°ì„", "ì†Œì†¡ ì œê¸°", "ì†í•´ë°°ìƒ", "ê±°ë˜ì •ì§€", "ìƒì¥íì§€", "ê°ì‚¬ì˜ê²¬ ê±°ì ˆ", "íŒŒì‚°", "íšŒìƒ"]
        for report in reports:
            if "ìœ ìƒì¦ì ê²°ì •" in report.report_nm and "ì œ3ìë°°ì •" in report.report_nm: continue 
            if any(keyword in report.report_nm for keyword in negative_keywords):
                return True, f"DART ê³µì‹œ ì•…ì¬: '{report.report_nm}'"
        return False, None
    except Exception as e:
        logging.error(f"DART ê³µì‹œ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ({corp_code}): {e}")
        return False, None

def check_for_negatives(fundamentals, headlines, code, corp_code):
    """ë‰´ìŠ¤/ì¬ë¬´/ê³µì‹œ ê¸°ë°˜ìœ¼ë¡œ ì•…ì¬ì„± ì¢…ëª© ì—¬ë¶€ë¥¼ ê²€ì‚¬"""
    
    negative_keywords_news = ["íš¡ë ¹", "ë°°ì„", "ì†Œì†¡", "ë¶„ìŸ", "ê±°ë˜ ì •ì§€", "ì•…ì¬", "í•˜ë½ ì „ë§", "íˆ¬ìì£¼ì˜", "ì ì"]
    for news in headlines:
        if any(keyword in news.get('title', '') for keyword in negative_keywords_news):
            return True, f"ë‰´ìŠ¤ ì•…ì¬: '{news.get('title')}'"
            
    roe = fundamentals.get('ROE')
    debt_to_equity = fundamentals.get('DebtToEquity')
    
    if roe is not None and roe < 0 and not pd.isna(roe): 
        return True, f"ì¬ë¬´ ì•…ì¬: ROE {roe:.1f}% (ì ì)"
    
    if debt_to_equity is not None and debt_to_equity > 150 and not pd.isna(debt_to_equity): 
        return True, f"ì¬ë¬´ ì•…ì¬: ë¶€ì±„ë¹„ìœ¨ {debt_to_equity:.1f}% ì´ˆê³¼ (150% ê¸°ì¤€)"

    is_negative_dart, reason_dart = check_for_negative_dart_disclosures(corp_code)
    if is_negative_dart: return True, reason_dart
        
    return False, None

# ==============================
# 6. ë¶„ì„ ì‹¤í–‰ ë° í•„í„°ë§
# ==============================

def check_ma_conditions(df, periods, analyze_patterns):
    """ì´ë™ í‰ê· ì„  ë° íŒ¨í„´ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    results = {}
    
    if len(df) < 200: analyze_patterns = False
        
    for p in periods:
        if len(df) >= p:
            df[f'ma{p}'] = df['Close'].rolling(window=p, min_periods=1).mean() 
            results[f"above_ma{p}"] = df['Close'].iloc[-1] > df[f'ma{p}'].iloc[-1]
    
    ma50_col = 'ma50'
    ma200_col = 'ma200'
    if ma50_col in df.columns and ma200_col in df.columns and len(df) >= 200:
        results["goldencross_50_200_detected"] = (df[ma50_col].iloc[-2] < df[ma200_col].iloc[-2] and df[ma50_col].iloc[-1] > df[ma200_col].iloc[-1])
    else:
         results["goldencross_50_200_detected"] = False
    
    if analyze_patterns:
        peaks, troughs = find_peaks_and_troughs(df)
        is_db, neckline_db, db_status, db_price = find_double_bottom(df, troughs)
        is_tb, neckline_tb, tb_status, tb_price = find_triple_bottom(df, troughs)
        is_ch, neckline_ch, ch_status, ch_price = find_cup_and_handle(df, peaks, troughs)
        
        results['pattern_double_bottom_status'] = db_status
        results['db_neckline_price'] = db_price

        results['pattern_triple_bottom_status'] = tb_status
        results['tb_neckline_price'] = tb_price

        results['pattern_cup_and_handle_status'] = ch_status
        results['ch_neckline_price'] = ch_price

    return results

def analyze_symbol(item, periods, analyze_patterns, exclude_negatives, pattern_type_filter):
    """ë‹¨ì¼ ì¢…ëª©ì„ ë¶„ì„í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    code = item.get("Code") or item.get("code")
    name = item.get("Name") or item.get("name")
    corp_code = item.get("DartCorpCode")
    path = DATA_DIR / f"{code}.parquet"
    if not path.exists(): return None
    
    try:
        df = pd.read_parquet(path)
        if len(df) < 50: return None

        fundamentals, headlines = get_fundamental_data(code)
        
        if exclude_negatives:
            is_negative, reason = check_for_negatives(fundamentals, headlines, code, corp_code)
            if is_negative:
                return None
        
        analysis_results = check_ma_conditions(df, periods, analyze_patterns) 
        
        is_match = True
        if pattern_type_filter:
            if pattern_type_filter == 'goldencross': 
                is_match = analysis_results.get("goldencross_50_200_detected", False)
            elif pattern_type_filter in ['double_bottom', 'triple_bottom', 'cup_and_handle']: 
                status_key = f'pattern_{pattern_type_filter}_status'
                status = analysis_results.get(status_key)
                is_match = status in ['Breakout', 'Potential']
            elif pattern_type_filter == 'ma':
                pass 
            else:
                is_match = False

        if not is_match: return None
        
        if analysis_results or fundamentals or headlines:
            fundamentals_clean = {k: v for k, v in fundamentals.items() if v is not None and not (isinstance(v, (float, np.float64)) and np.isnan(v))}
            analysis_clean = {k: v for k, v in analysis_results.items() if v is not None and not (isinstance(v, (float, np.float64)) and np.isnan(v))}
            
            return {
                "ticker": code,
                "name": name,
                "technical_conditions": analysis_clean,
                "fundamentals": fundamentals_clean,
                "recent_news_headlines": headlines
            }
        return None
    except Exception as e:
        logging.error(f"[ERROR] {code} {name} ë¶„ì„ ì‹¤íŒ¨: {e}\n{traceback.format_exc()}")
        return None

def run_analysis(workers, ma_periods_str, analyze_patterns, exclude_negatives, pattern_type_filter):
    """ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ì´ìš©í•´ ì „ì²´ ì¢…ëª© ë¶„ì„ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    start_time = time.time()
    periods = [int(p.strip()) for p in ma_periods_str.split(',') if p.strip().isdigit()]
    if pattern_type_filter and pattern_type_filter != 'ma': analyze_patterns = True 
    if 50 not in periods: periods.append(50) 
    if 200 not in periods: periods.append(200)

    items = load_listing()
    results = []
    
    logging.info(f"ë¶„ì„ ì‹œì‘: ì´ {len(items)} ì¢…ëª©, ìµœëŒ€ ì›Œì»¤ {workers}ê°œ ì‚¬ìš©.")

    with ThreadPoolExecutor(max_workers=workers) as executor:
        future_to_item = {
            executor.submit(analyze_symbol, item, periods, analyze_patterns, exclude_negatives, pattern_type_filter): item
            for item in items
        }
        
        for future in as_completed(future_to_item):
            item = future_to_item[future]
            try:
                r = future.result()
                if r: results.append(r)
            except Exception as e:
                code = item.get("Code") or item.get("code")
                name = item.get("Name") or item.get("name")
                logging.error(f"[ERROR] {code} {name} ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
    
    end_time = time.time()
    logging.info(f"ë¶„ì„ ì™„ë£Œ: {len(results)}ê°œ ì¢…ëª© í•„í„°ë§ ë¨. ì´ ì†Œìš” ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
    safe_print_json({"results": results, "mode": "analyze", "filter": pattern_type_filter or 'ma_only'})

def generate_chart(symbol, ma_periods_str):
    """ë‹¨ì¼ ì¢…ëª©ì˜ ì°¨íŠ¸ë¥¼ ìƒì„±í•˜ê³  Base64ë¡œ ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    code = symbol
    name = get_stock_name(code)
    periods = [int(p.strip()) for p in ma_periods_str.split(',') if p.strip().isdigit()]
    path = DATA_DIR / f"{code}.parquet"
    if not path.exists():
        safe_print_json({"error": f"ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {path}"})
        return
    try:
        df = pd.read_parquet(path)
        if df.empty:
            safe_print_json({"error": "ë°ì´í„°í”„ë ˆì„ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤."})
            return
        
        df = df.iloc[-250:].copy() 
        ma_lines = []
        for p in periods:
            if len(df) >= p:
                ma_name = f'ma{p}'
                df[ma_name] = df['Close'].rolling(window=p, min_periods=1).mean()
                ma_lines.append(mpf.make_addplot(df[ma_name], panel=0, type='line', width=1.0, color='blue' if p == 200 else ('green' if p == 50 else 'orange'), secondary_y=False))
        
        volume_plot = mpf.make_addplot(df['Volume'], type='bar', panel=1, color='gray', secondary_y=False)
        mc = mpf.make_marketcolors(up='red', down='blue', wick='black', edge='black', volume='gray')
        s = mpf.make_mpf_style(marketcolors=mc, gridcolor='gray', figcolor='white', y_on_right=False, 
                               rc={'font.family': MPLFINANCE_FONT})
        
        addplots = ma_lines + [volume_plot]
        
        fig, axes = mpf.plot(df, type='candle', style=s, 
                             title=f"{name} ({code}) Price Chart with MAs", 
                             ylabel='Price', ylabel_lower='Volume', volume=True, 
                             addplot=addplots, figscale=1.5, returnfig=True)
        
        buf = io.BytesIO()
        fig.savefig(buf, format='png', bbox_inches='tight')
        plt.close(fig)
        image_base64 = base64.b64encode(buf.getvalue()).decode('utf-8')
        
        safe_print_json({"ticker": code, "name": name, "chart_image_base64": image_base64, "mode": "chart"})
        
    except Exception as e:
        logging.error(f"[ERROR] ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨ ({code} {name}): {e}\n{traceback.format_exc()}")
        safe_print_json({"error": f"ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}"})

def main():
    parser = argparse.ArgumentParser(description="ì£¼ì‹ ë°ì´í„° ë¶„ì„ ë° ì°¨íŠ¸ ìƒì„± ìŠ¤í¬ë¦½íŠ¸")
    parser.add_argument("--mode", type=str, required=True, choices=['analyze', 'chart'], help="ì‹¤í–‰ ëª¨ë“œ ì„ íƒ: 'analyze' ë˜ëŠ” 'chart'")
    parser.add_argument("--workers", type=int, default=os.cpu_count() * 2, help="ë¶„ì„ ëª¨ë“œì—ì„œ ì‚¬ìš©í•  ìµœëŒ€ ìŠ¤ë ˆë“œ ìˆ˜")
    parser.add_argument("--ma_periods", type=str, default="50,200", help="ì´ë™ í‰ê· ì„  ê¸°ê°„ ì§€ì • (ì‰¼í‘œë¡œ êµ¬ë¶„)")
    parser.add_argument("--symbol", type=str, help="ì°¨íŠ¸ ëª¨ë“œì—ì„œ ì‚¬ìš©í•  ì¢…ëª© ì½”ë“œ")
    parser.add_argument("--analyze_patterns", action="store_true", help="íŒ¨í„´ ê°ì§€ í™œì„±í™”")
    parser.add_argument("--pattern_type", type=str, choices=['ma', 'double_bottom', 'triple_bottom', 'cup_and_handle', 'goldencross'], help="í•„í„°ë§í•  íŒ¨í„´ ì¢…ë¥˜")
    parser.add_argument("--exclude_negatives", action="store_true", help="ì•…ì¬ì„± ì¢…ëª© ì œì™¸")
    args = parser.parse_args()
    
    try:
        if args.mode == 'analyze':
            run_analysis(args.workers, args.ma_periods, args.analyze_patterns, args.exclude_negatives, args.pattern_type) 
        elif args.mode == 'chart':
            if not args.symbol: 
                logging.error("ì°¨íŠ¸ ëª¨ë“œì—ëŠ” --symbol ì¸ìˆ˜ê°€ í•„ìˆ˜ì…ë‹ˆë‹¤.")
                sys.exit(1)
            generate_chart(args.symbol, args.ma_periods) 
    except Exception as e:
        error_msg = f"ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e}"
        logging.critical(f"{error_msg}\n{traceback.format_exc()}")
        safe_print_json({"error": error_msg})
        sys.exit(1)

if __name__ == "__main__":
    main()